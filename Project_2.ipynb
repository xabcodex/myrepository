{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROJECT 2\n",
    "\n",
    "A project of the dataquest course\n",
    "\n",
    "Until now we have learned:\n",
    "- How to work with strings\n",
    "- Object oriented programming\n",
    "- Dates and times\n",
    "\n",
    "In this project I am going to work with a dataset of submissions to popular technology site [Hacker News](https://news.ycombinator.com)\n",
    "\n",
    "It is a webpage similar to reddit. It is really popular in technology and startups.\n",
    "\n",
    "The dataset is going to be used is [here](https://www.kaggle.com/hacker-news/hacker-news-posts).\n",
    "\n",
    "The meanings of the columns are the following ones:\n",
    "\n",
    "- id: The identifier from Hacker news for the post\n",
    "- title: The title of the post\n",
    "- url: The URL that the posts links to\n",
    "- num_points: The number of points the post acquired, calculated between the upvotes and the downvotes\n",
    "- num_comments: The number of comments that were made on the post\n",
    "- author: The username of the person who submitted the post\n",
    "- created_at: The date and time at which the post was submitted\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01'], ['10301696', 'Note by Note: The Making of Steinway L1037 (2007)', 'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0', '8', '2', 'walterbell', '9/30/2015 4:12']]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "#opened_file = open('HN_posts_year_to_Sep_26_2016.csv')\n",
    "opened_file = open('hacker_news.csv')\n",
    "read_file = csv.reader(opened_file)\n",
    "dataset_org = list(read_file)\n",
    "\n",
    "num_rows = len(dataset_org)\n",
    "num_cols = len(dataset_org[0])\n",
    "print(dataset_org[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will remove the header of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01'], ['10301696', 'Note by Note: The Making of Steinway L1037 (2007)', 'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0', '8', '2', 'walterbell', '9/30/2015 4:12'], ['10482257', 'Title II kills investment? Comcast and other ISPs are now spending more', 'http://arstechnica.com/business/2015/10/comcast-and-other-isps-boost-network-investment-despite-net-neutrality/', '53', '22', 'Deinos', '10/31/2015 9:48']]\n"
     ]
    }
   ],
   "source": [
    "#header = dataset_org[0]\n",
    "#dataset_no_header = dataset_org[1:]\n",
    "#print(header)\n",
    "#print('\\n')\n",
    "print(dataset_no_header[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is going to be performed the separation of the rows which start with **Ask HN** or **Show HN**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of posts in ask_posts is 1744, in show posts is 1162 and the other ones are 17193\n"
     ]
    }
   ],
   "source": [
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "for row in dataset_no_header:\n",
    "    title = row[1]\n",
    "    if title.lower().startswith('ask hn'):\n",
    "        ask_posts.append(row)\n",
    "    elif title.lower().startswith('show hn'):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "        \n",
    "num_ask_posts = len(ask_posts)\n",
    "num_show_posts = len(show_posts)\n",
    "num_other_posts = len(other_posts)\n",
    "        \n",
    "print('The number of posts in ask_posts is {ask}, in show posts is {show} and the other ones are {other}'.format(ask = num_ask_posts , show = num_show_posts , other = num_other_posts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this section, is going to be checked if the average comments of Ask HN is bigger than Show HN.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this cell, a function is defined in order to perform the average of the number of comments on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comments_avg(dataset_without_header):\n",
    "    total_ask_comments = 0\n",
    "    for row in dataset_without_header:\n",
    "        total_ask_comments += int(row[4])\n",
    "    avg = total_ask_comments / len(dataset_without_header)\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average value of the comments in Ask HN is: 14.038417431192661\n",
      "The average value of the comments in Show HN is: 10.31669535283993\n"
     ]
    }
   ],
   "source": [
    "avg_ask_comments = comments_avg(ask_posts)\n",
    "print('The average value of the comments in Ask HN is: ' + str(avg_ask_comments))\n",
    "avg_show_comments = comments_avg(show_posts)\n",
    "print('The average value of the comments in Show HN is: ' + str(avg_show_comments))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the Ask HN posts receive more comments on average. I am going to focus on this dataset.\n",
    "\n",
    "So now, it will be going to determine if ask posts created at a certain time are more likely to attract comments or not. For that, the following steps will be performed:\n",
    "\n",
    "- Calculate the number of posts performed in each hour of the day, with the number of comments received.\n",
    "- Calculate the average number of the posts in each hour.\n",
    "\n",
    "For that [datetime module](https://docs.python.org/3/library/datetime.html) will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts by hour:\n",
      "{'09': 45, '13': 85, '10': 59, '14': 107, '16': 108, '23': 68, '12': 73, '17': 100, '15': 116, '21': 109, '20': 80, '02': 58, '18': 109, '03': 54, '05': 46, '19': 110, '01': 60, '22': 71, '08': 48, '04': 47, '00': 55, '06': 44, '07': 34, '11': 58}\n",
      "Comments by hour:\n",
      "{'09': 251, '13': 1253, '10': 793, '14': 1416, '16': 1814, '23': 543, '12': 687, '17': 1146, '15': 4477, '21': 1745, '20': 1722, '02': 1381, '18': 1439, '03': 421, '05': 464, '19': 1188, '01': 683, '22': 479, '08': 492, '04': 337, '00': 447, '06': 397, '07': 267, '11': 641}\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "result_list = []\n",
    "for row in ask_posts:\n",
    "    list = [row[6] , int(row[4])]\n",
    "    result_list.append(list)\n",
    "    \n",
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "\n",
    "for row in result_list:\n",
    "    date = dt.datetime.strptime(row[0] , '%m/%d/%Y %H:%M')\n",
    "    row[0] = date\n",
    "    hour = date.strftime('%H')\n",
    "    if hour in counts_by_hour:\n",
    "        counts_by_hour[hour] += 1\n",
    "        comments_by_hour[hour] += row[1]\n",
    "    else:\n",
    "        counts_by_hour[hour] = 1\n",
    "        comments_by_hour[hour] = row[1]\n",
    "print('Counts by hour:')\n",
    "print(counts_by_hour)\n",
    "print('Comments by hour:')\n",
    "print(comments_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the las cell there has been created two dictionaries. Now those two dictionaries are going to be used for calculating the average number of comments for posts created during each hour of the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average comments for the posts created in each hour is:\n",
      "[['09', 5.5777777777777775], ['13', 14.741176470588234], ['10', 13.440677966101696], ['14', 13.233644859813085], ['16', 16.796296296296298], ['23', 7.985294117647059], ['12', 9.41095890410959], ['17', 11.46], ['15', 38.5948275862069], ['21', 16.009174311926607], ['20', 21.525], ['02', 23.810344827586206], ['18', 13.20183486238532], ['03', 7.796296296296297], ['05', 10.08695652173913], ['19', 10.8], ['01', 11.383333333333333], ['22', 6.746478873239437], ['08', 10.25], ['04', 7.170212765957447], ['00', 8.127272727272727], ['06', 9.022727272727273], ['07', 7.852941176470588], ['11', 11.051724137931034]]\n"
     ]
    }
   ],
   "source": [
    "avg_by_hour = []\n",
    "for key in comments_by_hour:\n",
    "    avg_by_hour.append([key , comments_by_hour[key] / counts_by_hour[key]])\n",
    "    \n",
    "\n",
    "print('The average comments for the posts created in each hour is:')\n",
    "print(avg_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's sort the result using [sorted function](https://docs.python.org/3/library/functions.html#sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.5777777777777775, '09'], [14.741176470588234, '13'], [13.440677966101696, '10'], [13.233644859813085, '14'], [16.796296296296298, '16'], [7.985294117647059, '23'], [9.41095890410959, '12'], [11.46, '17'], [38.5948275862069, '15'], [16.009174311926607, '21'], [21.525, '20'], [23.810344827586206, '02'], [13.20183486238532, '18'], [7.796296296296297, '03'], [10.08695652173913, '05'], [10.8, '19'], [11.383333333333333, '01'], [6.746478873239437, '22'], [10.25, '08'], [7.170212765957447, '04'], [8.127272727272727, '00'], [9.022727272727273, '06'], [7.852941176470588, '07'], [11.051724137931034, '11']]\n",
      "Top 5 Hours for Ask Posts Comments\n",
      "15:00: 38.59 average comments per post\n",
      "02:00: 23.81 average comments per post\n",
      "20:00: 21.52 average comments per post\n",
      "16:00: 16.80 average comments per post\n",
      "21:00: 16.01 average comments per post\n"
     ]
    }
   ],
   "source": [
    "swap_avg_by_hour = []\n",
    "for row in avg_by_hour:\n",
    "    swap_avg_by_hour.append([row[1] , row[0]])\n",
    "    \n",
    "print(swap_avg_by_hour)\n",
    "sorted_swap = sorted(swap_avg_by_hour , reverse = True)\n",
    "\n",
    "print('Top 5 Hours for Ask Posts Comments')\n",
    "hours = []\n",
    "for row in sorted_swap[:5]:\n",
    "    hour = dt.datetime.strptime(row[1] , '%H')\n",
    "    hours.append([hour , row [0]])\n",
    "    hour_string = hour.strftime('%H:%M')\n",
    "    print('{h}: {avg_string:.2f} average comments per post'.format(h = hour_string , avg_string = row[0]))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the time is in Eastern time in the US. Is going to be changed to Madrid time zone. For that, 5h must be sumed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 hours for Ask posts comments in Spain\n",
      "20:00: 38.59 average comments per post in spain time zone\n",
      "07:00: 23.81 average comments per post in spain time zone\n",
      "01:00: 21.52 average comments per post in spain time zone\n",
      "21:00: 16.80 average comments per post in spain time zone\n",
      "02:00: 16.01 average comments per post in spain time zone\n"
     ]
    }
   ],
   "source": [
    "print('Top 5 hours for Ask posts comments in Spain')\n",
    "for row in hours:\n",
    "    spain_hour = row[0] + dt.timedelta(hours = 5)\n",
    "    hour_string_sp = spain_hour.strftime('%H:%M')\n",
    "    print('{h1}: {avg_string1:.2f} average comments per post in spain time zone'.format(h1 = hour_string_sp , avg_string1 = row[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is where the guided project with dataquest is finished. However the study performed to this dataset will continue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To know if show or ask posts receive more points on average the following function is done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def points_avg(dataset):\n",
    "    total_points = 0\n",
    "    for row in dataset:\n",
    "        total_points += int(row[3])\n",
    "    avg = total_points / len(dataset)\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average value of the points in Ask HN is: 15.061926605504587\n",
      "The average value of the points in Show HN is: 27.555077452667813\n"
     ]
    }
   ],
   "source": [
    "avg_ask_points = points_avg(ask_posts)\n",
    "print('The average value of the points in Ask HN is: ' + str(avg_ask_points))\n",
    "avg_show_points = points_avg(show_posts)\n",
    "print('The average value of the points in Show HN is: ' + str(avg_show_points))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In the previous cell is shown that the Show HN are more likely to obtain points that Ask HN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the following cell wil be performed the check of in which time are more likely to receive more points the posts of Ask and Show."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts by hour:\n",
      "{'09': 45, '13': 85, '10': 59, '14': 107, '16': 108, '23': 68, '12': 73, '17': 100, '15': 116, '21': 109, '20': 80, '02': 58, '18': 109, '03': 54, '05': 46, '19': 110, '01': 60, '22': 71, '08': 48, '04': 47, '00': 55, '06': 44, '07': 34, '11': 58}\n",
      "Points by hour:\n",
      "{'09': 329, '13': 2062, '10': 1102, '14': 1282, '16': 2522, '23': 581, '12': 782, '17': 1941, '15': 3479, '21': 1721, '20': 1151, '02': 793, '18': 1741, '03': 374, '05': 552, '19': 1513, '01': 700, '22': 511, '08': 515, '04': 389, '00': 451, '06': 591, '07': 361, '11': 825}\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "result_list = []\n",
    "for row in ask_posts:\n",
    "    list = [row[6] , int(row[3])]\n",
    "    result_list.append(list)\n",
    "    \n",
    "counts_by_hour = {}\n",
    "points_by_hour = {}\n",
    "\n",
    "for row in result_list:\n",
    "    date = dt.datetime.strptime(row[0] , '%m/%d/%Y %H:%M')\n",
    "    row[0] = date\n",
    "    hour = date.strftime('%H')\n",
    "    if hour in counts_by_hour:\n",
    "        counts_by_hour[hour] += 1\n",
    "        points_by_hour[hour] += row[1]\n",
    "    else:\n",
    "        counts_by_hour[hour] = 1\n",
    "        points_by_hour[hour] = row[1]\n",
    "print('Counts by hour:')\n",
    "print(counts_by_hour)\n",
    "print('Points by hour:')\n",
    "print(comments_by_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average comments for the posts created in each hour is:\n",
      "[['09', 7.311111111111111], ['13', 24.258823529411764], ['10', 18.677966101694917], ['14', 11.981308411214954], ['16', 23.35185185185185], ['23', 8.544117647058824], ['12', 10.712328767123287], ['17', 19.41], ['15', 29.99137931034483], ['21', 15.788990825688073], ['20', 14.3875], ['02', 13.672413793103448], ['18', 15.972477064220184], ['03', 6.925925925925926], ['05', 12.0], ['19', 13.754545454545454], ['01', 11.666666666666666], ['22', 7.197183098591549], ['08', 10.729166666666666], ['04', 8.27659574468085], ['00', 8.2], ['06', 13.431818181818182], ['07', 10.617647058823529], ['11', 14.224137931034482]]\n"
     ]
    }
   ],
   "source": [
    "avg_by_hour = []\n",
    "for key in points_by_hour:\n",
    "    avg_by_hour.append([key , points_by_hour[key] / counts_by_hour[key]])\n",
    "    \n",
    "\n",
    "print('The average comments for the posts created in each hour is:')\n",
    "print(avg_by_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.311111111111111, '09'], [24.258823529411764, '13'], [18.677966101694917, '10'], [11.981308411214954, '14'], [23.35185185185185, '16'], [8.544117647058824, '23'], [10.712328767123287, '12'], [19.41, '17'], [29.99137931034483, '15'], [15.788990825688073, '21'], [14.3875, '20'], [13.672413793103448, '02'], [15.972477064220184, '18'], [6.925925925925926, '03'], [12.0, '05'], [13.754545454545454, '19'], [11.666666666666666, '01'], [7.197183098591549, '22'], [10.729166666666666, '08'], [8.27659574468085, '04'], [8.2, '00'], [13.431818181818182, '06'], [10.617647058823529, '07'], [14.224137931034482, '11']]\n",
      "Top 5 Hours for Ask Posts Points\n",
      "15:00: 29.99 average points per post\n",
      "13:00: 24.26 average points per post\n",
      "16:00: 23.35 average points per post\n",
      "17:00: 19.41 average points per post\n",
      "10:00: 18.68 average points per post\n"
     ]
    }
   ],
   "source": [
    "swap_avg_by_hour = []\n",
    "for row in avg_by_hour:\n",
    "    swap_avg_by_hour.append([row[1] , row[0]])\n",
    "    \n",
    "print(swap_avg_by_hour)\n",
    "sorted_swap = sorted(swap_avg_by_hour , reverse = True)\n",
    "\n",
    "print('Top 5 Hours for Ask Posts Points')\n",
    "hours = []\n",
    "for row in sorted_swap[:5]:\n",
    "    hour = dt.datetime.strptime(row[1] , '%H')\n",
    "    hours.append([hour , row [0]])\n",
    "    hour_string = hour.strftime('%H:%M')\n",
    "    print('{h}: {avg_string:.2f} average points per post'.format(h = hour_string , avg_string = row[0]))\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 hours for Ask posts points in Spain\n",
      "20:00: 29.99 average points per post in spain time zone\n",
      "18:00: 24.26 average points per post in spain time zone\n",
      "21:00: 23.35 average points per post in spain time zone\n",
      "22:00: 19.41 average points per post in spain time zone\n",
      "15:00: 18.68 average points per post in spain time zone\n"
     ]
    }
   ],
   "source": [
    "print('Top 5 hours for Ask posts points in Spain')\n",
    "for row in hours:\n",
    "    spain_hour = row[0] + dt.timedelta(hours = 5)\n",
    "    hour_string_sp = spain_hour.strftime('%H:%M')\n",
    "    print('{h1}: {avg_string1:.2f} average points per post in spain time zone'.format(h1 = hour_string_sp , avg_string1 = row[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
